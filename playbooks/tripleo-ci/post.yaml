---
- name: Return Zuul artifacts
  hosts: primary
  roles:
    - tripleo-ci-post

- name: Write console log to localhost as fact zuul_console_json
  hosts: localhost
  tasks:
    - name: capture console log json as fact
      set_fact:
        zuul_console_json: "{{ lookup('file', zuul.executor.log_root + '/job-output.json') }}"

- name: Generate build report for the container build
  hosts: primary
  tasks:
    - name: "Create log directory"
      file:
        path: "{{ ansible_user_dir }}/workspace/logs"
        state: directory
        recurse: true

    - name: Build report (content provider)
      include_role:
        name: build-containers
        tasks_from: build-report
      when:
        - ansible_distribution_major_version is version('8', '>=')
        - provider_job | default(false) | bool

    - name: Check that the report.html exists
      stat:
        path: "{{ ansible_user_dir }}/workspace/logs/report.html"
      register: stat_report_result

    - name: Return report.html artifact to Zuul
      zuul_return:
        data:
          zuul:
            artifacts:
              - name: "Build report"
                url: "logs/report.html"
                metadata:
                  type: build_report
      when: stat_report_result.stat.exists

- name: Collect logs
  hosts: primary
  tasks:
    - name: set collection timeout
      set_fact:
        collect_timeout_sec: "{{ zuul.post_timeout|default(3600) -  copy_logs_time|default(300) }}"

    - name: Copy zuul_console_json log to workspace for reproducer
      copy:
        content: "{{ hostvars['localhost'].zuul_console_json }}"
        dest: "{{ ansible_user_dir }}/workspace/logs/zuul_console.json"

    - name: Check for artifacts created by a previous collect_logs
      stat:
        path: "{{ ansible_user_dir  }}/workspace/logs/undercloud"
      register: undercloud_logs

    # Collect logs in ovb needs to run before te broker deletes the overcloud nodes.
    # if a timeout happens, collect logs will not run, overcloud nodes will get deleted
    # and we'll not even get undercloud logs
    # Check if we have and undercloud dir in logs. If not, launch collect logs.
    # TODO(gcerami) find a way to run collect logs before te broker deletes the env in
    # case of timeout.
    - name: Remark of collect logs running before post in ovb
      debug:
        msg: "OVB job collect logs already run, not running collect_logs in post"
      when: environment_type == "ovb" and undercloud_logs.stat.exists

    - name: Run ansible playbook to collect logs for ovb jobs that weren't able to run collect logs
      shell: |
        if [[ -e {{ ansible_user_dir }}/workspace/logs/collect_logs.sh ]]; then
          bash {{ ansible_user_dir }}/workspace/logs/collect_logs.sh
          mv {{ ansible_user_dir }}/workspace/logs/collect_logs.sh {{ ansible_user_dir }}/workspace/logs/ovb_collect_logs.sh
        fi
      when: environment_type == "ovb" and not undercloud_logs.stat.exists

    - name: Check script existence
      stat:
        path: "{{ ansible_user_dir  }}/workspace/logs/collect_logs.sh"
      register: collect_logs_path

    - name: Collect logs with a timeout
      block:
        - name: Run ansible playbook to collect logs
          command: |
              timeout --preserve-status -s 15 \
                -k {{ [collect_timeout_sec|int, 60]|sum|string }} {{ collect_timeout_sec|string }} \
                bash {{ ansible_user_dir }}/workspace/logs/collect_logs.sh
          when: collect_logs_path.stat.exists
          register: collect_logs_run

      rescue:
        - name: warn when collect logs timed out (SIGTERM or SIGKILL used)
          debug:
            msg: "ERROR: Collect logs timed out"
          when: collect_logs_path.stat.exists and (collect_logs_run.rc == 143 or collect_logs_run.rc == 137)

        - name: warn when collect logs failed
          debug:
            msg: "ERROR: Collect logs failed, please check the logs"
          when: collect_logs_path.stat.exists and collect_logs_run.rc != 143 and collect_logs_run.rc != 137

      always:
        - name: Ensure artifacts directory exists
          file:
            path: '{{ zuul.executor.work_root }}/artifacts'
            state: directory
          delegate_to: localhost

        - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
          no_log: true
          failed_when: false
          synchronize:
            src: '{{ ansible_user_dir }}/workspace/'
            dest: '{{ zuul.executor.log_root }}'
            mode: pull
            copy_links: true
            verify_host: true
            rsync_opts:
              - --include=/logs/**
              - --include=*/
              - --exclude=*
              - --prune-empty-dirs

    - name: Fail job when logs collection fail and it's critical
      fail:
        msg: "ERROR: Collect logs failed and job is configured to fail!"
      when:
        - collect_logs_path.stat.exists
        - collect_logs_run.rc != 0
        - fail_logs_collection|default(false)|bool
        - zuul.pipeline|default('') != 'gate'
